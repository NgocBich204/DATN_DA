
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple


class SegmentReasoningEngine:
    """
    Engine t·ª± ƒë·ªông t·∫°o l√Ω do ch·ªçn ph√¢n kh√∫c d·ª±a tr√™n:
    - ƒê·∫∑c ƒëi·ªÉm RFM c·ªßa cluster
    - Ph√¢n t√≠ch so s√°nh v·ªõi c√°c cluster kh√°c
    - Best practices trong CRM/Marketing
    """

    def __init__(self):
        # Ng∆∞·ª°ng ph√¢n lo·∫°i (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh d·ª±a tr√™n d·ªØ li·ªáu)
        self.recency_thresholds = {
            'very_recent': 30,
            'recent': 90,
            'moderate': 180,
            'long_ago': 365
        }

        self.frequency_thresholds = {
            'very_high': 20,
            'high': 10,
            'moderate': 5,
            'low': 2
        }

        self.monetary_percentiles = {
            'very_high': 90,
            'high': 75,
            'moderate': 50,
            'low': 25
        }

    def analyze_rfm_profile(self, segment_data: pd.DataFrame,
                            all_data: pd.DataFrame) -> Dict:
        """
        Ph√¢n t√≠ch profile RFM c·ªßa m·ªôt segment

        Args:
            segment_data: DataFrame ch·ª©a d·ªØ li·ªáu c·ªßa segment
            all_data: DataFrame ch·ª©a to√†n b·ªô d·ªØ li·ªáu ƒë·ªÉ so s√°nh

        Returns:
            Dict ch·ª©a c√°c ƒë·∫∑c ƒëi·ªÉm RFM
        """
        profile = {}

        # Recency Analysis
        avg_recency = segment_data['Recency'].mean()
        median_recency = segment_data['Recency'].median()
        recency_percentile = (
            all_data['Recency'] <= avg_recency).sum() / len(all_data) * 100

        if avg_recency <= self.recency_thresholds['very_recent']:
            profile['recency_level'] = 'r·∫•t g·∫ßn ƒë√¢y'
            profile['recency_score'] = 5
        elif avg_recency <= self.recency_thresholds['recent']:
            profile['recency_level'] = 'g·∫ßn ƒë√¢y'
            profile['recency_score'] = 4
        elif avg_recency <= self.recency_thresholds['moderate']:
            profile['recency_level'] = 'trung b√¨nh'
            profile['recency_score'] = 3
        elif avg_recency <= self.recency_thresholds['long_ago']:
            profile['recency_level'] = 'l√¢u'
            profile['recency_score'] = 2
        else:
            profile['recency_level'] = 'r·∫•t l√¢u'
            profile['recency_score'] = 1

        profile['avg_recency'] = avg_recency
        profile['recency_percentile'] = recency_percentile

        # Frequency Analysis
        avg_frequency = segment_data['Frequency'].mean()
        median_frequency = segment_data['Frequency'].median()
        frequency_percentile = (
            all_data['Frequency'] <= avg_frequency).sum() / len(all_data) * 100

        if avg_frequency >= self.frequency_thresholds['very_high']:
            profile['frequency_level'] = 'r·∫•t cao'
            profile['frequency_score'] = 5
        elif avg_frequency >= self.frequency_thresholds['high']:
            profile['frequency_level'] = 'cao'
            profile['frequency_score'] = 4
        elif avg_frequency >= self.frequency_thresholds['moderate']:
            profile['frequency_level'] = 'trung b√¨nh'
            profile['frequency_score'] = 3
        elif avg_frequency >= self.frequency_thresholds['low']:
            profile['frequency_level'] = 'th·∫•p'
            profile['frequency_score'] = 2
        else:
            profile['frequency_level'] = 'r·∫•t th·∫•p'
            profile['frequency_score'] = 1

        profile['avg_frequency'] = avg_frequency
        profile['frequency_percentile'] = frequency_percentile

        # Monetary Analysis
        avg_monetary = segment_data['Monetary'].mean()
        median_monetary = segment_data['Monetary'].median()
        monetary_percentile = (
            all_data['Monetary'] <= avg_monetary).sum() / len(all_data) * 100

        if monetary_percentile >= self.monetary_percentiles['very_high']:
            profile['monetary_level'] = 'r·∫•t cao'
            profile['monetary_score'] = 5
        elif monetary_percentile >= self.monetary_percentiles['high']:
            profile['monetary_level'] = 'cao'
            profile['monetary_score'] = 4
        elif monetary_percentile >= self.monetary_percentiles['moderate']:
            profile['monetary_level'] = 'trung b√¨nh'
            profile['monetary_score'] = 3
        elif monetary_percentile >= self.monetary_percentiles['low']:
            profile['monetary_level'] = 'th·∫•p'
            profile['monetary_score'] = 2
        else:
            profile['monetary_level'] = 'r·∫•t th·∫•p'
            profile['monetary_score'] = 1

        profile['avg_monetary'] = avg_monetary
        profile['monetary_percentile'] = monetary_percentile

        # T√≠nh t·ªïng ƒëi·ªÉm RFM
        profile['total_rfm_score'] = (
            profile['recency_score'] +
            profile['frequency_score'] +
            profile['monetary_score']
        )

        # Ph√¢n lo·∫°i segment d·ª±a tr√™n ƒëi·ªÉm RFM
        if profile['total_rfm_score'] >= 13:
            profile['segment_tier'] = 'VIP/Champions'
        elif profile['total_rfm_score'] >= 10:
            profile['segment_tier'] = 'Loyal Customers'
        elif profile['total_rfm_score'] >= 7:
            profile['segment_tier'] = 'Potential Loyalists'
        elif profile['total_rfm_score'] >= 5:
            profile['segment_tier'] = 'At Risk'
        else:
            profile['segment_tier'] = 'Lost/Hibernating'

        return profile

    def calculate_segment_characteristics(self, segment_data: pd.DataFrame,
                                          all_data: pd.DataFrame) -> Dict:
        """
        T√≠nh to√°n c√°c ƒë·∫∑c ƒëi·ªÉm b·ªï sung c·ªßa segment
        """
        characteristics = {}

        # T·ª∑ l·ªá kh√°ch h√†ng trong segment
        characteristics['size_percentage'] = len(
            segment_data) / len(all_data) * 100

        # ƒê√≥ng g√≥p doanh thu
        characteristics['revenue_contribution'] = (
            segment_data['Monetary'].sum() / all_data['Monetary'].sum() * 100
        )

        # CLV ∆∞·ªõc t√≠nh (Customer Lifetime Value)
        characteristics['avg_clv'] = segment_data['Monetary'].mean(
        ) * segment_data['Frequency'].mean()

        # T·ª∑ l·ªá churn risk (d·ª±a tr√™n Recency)
        high_recency_count = (segment_data['Recency'] > 180).sum()
        characteristics['churn_risk_percentage'] = high_recency_count / \
            len(segment_data) * 100

        # T√≠nh ƒë·ªô ƒë·ªìng nh·∫•t c·ªßa segment (Coefficient of Variation)
        characteristics['recency_cv'] = segment_data['Recency'].std(
        ) / segment_data['Recency'].mean()
        characteristics['frequency_cv'] = segment_data['Frequency'].std(
        ) / segment_data['Frequency'].mean()
        characteristics['monetary_cv'] = segment_data['Monetary'].std(
        ) / segment_data['Monetary'].mean()

        # ƒê·ªô ƒë·ªìng nh·∫•t trung b√¨nh (c√†ng th·∫•p c√†ng ƒë·ªìng nh·∫•t)
        characteristics['cohesion_score'] = np.mean([
            characteristics['recency_cv'],
            characteristics['frequency_cv'],
            characteristics['monetary_cv']
        ])

        return characteristics

    def generate_segment_reasoning(self, segment_id: int,
                                   segment_data: pd.DataFrame,
                                   all_data: pd.DataFrame,
                                   cluster_centers: np.ndarray = None) -> str:
        """
        T·∫°o l√Ω do ch·ªçn ph√¢n kh√∫c d·ª±a tr√™n ph√¢n t√≠ch RFM v√† K-means

        Args:
            segment_id: ID c·ªßa segment
            segment_data: D·ªØ li·ªáu c·ªßa segment
            all_data: To√†n b·ªô d·ªØ li·ªáu
            cluster_centers: T√¢m c·ªßa c√°c cluster t·ª´ K-means (optional)

        Returns:
            String ch·ª©a l√Ω do chi ti·∫øt
        """
        # Ph√¢n t√≠ch RFM profile
        rfm_profile = self.analyze_rfm_profile(segment_data, all_data)
        characteristics = self.calculate_segment_characteristics(
            segment_data, all_data)

        # T√≠nh CLV trung b√¨nh c·ªßa to√†n b·ªô data ƒë·ªÉ so s√°nh
        all_data_avg_clv = (
            all_data['Monetary'].mean() * all_data['Frequency'].mean())

        # B·∫Øt ƒë·∫ßu x√¢y d·ª±ng l√Ω do
        reasons = []

        # 1. Gi·ªõi thi·ªáu segment
        reasons.append(
            f"**Ph√¢n kh√∫c {segment_id}** ({rfm_profile['segment_tier']}) chi·∫øm {characteristics['size_percentage']:.1f}% t·ªïng kh√°ch h√†ng")

        # 2. Ph√¢n t√≠ch RFM chi ti·∫øt
        rfm_analysis = self._build_rfm_analysis(rfm_profile)
        reasons.append(rfm_analysis)

        # 3. Gi√° tr·ªã kinh doanh
        business_value = self._build_business_value_analysis(
            rfm_profile, characteristics, all_data_avg_clv)
        reasons.append(business_value)

        # 4. ƒê·∫∑c ƒëi·ªÉm h√†nh vi
        behavior_insight = self._build_behavior_insight(
            rfm_profile, characteristics)
        reasons.append(behavior_insight)

        # 5. Chi·∫øn l∆∞·ª£c ƒë·ªÅ xu·∫•t
        strategy = self._build_strategy_recommendation(
            rfm_profile, characteristics)
        reasons.append(strategy)

        # 6. ƒê·ªô ∆∞u ti√™n v√† ROI ti·ªÅm nƒÉng
        priority = self._build_priority_assessment(
            rfm_profile, characteristics)
        reasons.append(priority)

        return "\n\n".join(reasons)

    def _build_rfm_analysis(self, profile: Dict) -> str:
        """X√¢y d·ª±ng ph√¢n t√≠ch RFM"""
        analysis_parts = []

        # Recency
        if profile['recency_score'] >= 4:
            analysis_parts.append(
                f"Kh√°ch h√†ng c√≥ ƒë·ªô t∆∞∆°ng t√°c **{profile['recency_level']}** "
                f"(trung b√¨nh {profile['avg_recency']:.0f} ng√†y), "
                f"thu·ªôc top {100-profile['recency_percentile']:.0f}% kh√°ch h√†ng active nh·∫•t"
            )
        else:
            analysis_parts.append(
                f"Kh√°ch h√†ng c√≥ xu h∆∞·ªõng **√≠t t∆∞∆°ng t√°c** "
                f"(trung b√¨nh {profile['avg_recency']:.0f} ng√†y t·ª´ l·∫ßn mua cu·ªëi), "
                f"c·∫ßn chi·∫øn l∆∞·ª£c re-engagement"
            )

        # Frequency
        if profile['frequency_score'] >= 4:
            analysis_parts.append(
                f"T·∫ßn su·∫•t mua h√†ng **{profile['frequency_level']}** "
                f"(trung b√¨nh {profile['avg_frequency']:.1f} ƒë∆°n h√†ng), "
                f"th·ªÉ hi·ªán s·ª± trung th√†nh cao"
            )
        elif profile['frequency_score'] >= 3:
            analysis_parts.append(
                f"T·∫ßn su·∫•t mua h√†ng **{profile['frequency_level']}** "
                f"({profile['avg_frequency']:.1f} ƒë∆°n h√†ng), "
                f"c√≥ ti·ªÅm nƒÉng ph√°t tri·ªÉn th√†nh kh√°ch h√†ng th∆∞·ªùng xuy√™n"
            )
        else:
            analysis_parts.append(
                f"T·∫ßn su·∫•t mua h√†ng **{profile['frequency_level']}** "
                f"({profile['avg_frequency']:.1f} ƒë∆°n h√†ng), "
                f"c·∫ßn chi·∫øn l∆∞·ª£c khuy·∫øn kh√≠ch mua l·∫°i"
            )

        # Monetary
        if profile['monetary_score'] >= 4:
            analysis_parts.append(
                f"Gi√° tr·ªã chi ti√™u **{profile['monetary_level']}** "
                f"(${profile['avg_monetary']:,.0f} trung b√¨nh), "
                f"thu·ªôc top {100-profile['monetary_percentile']:.0f}% kh√°ch h√†ng c√≥ gi√° tr·ªã nh·∫•t"
            )
        else:
            analysis_parts.append(
                f"Gi√° tr·ªã chi ti√™u **{profile['monetary_level']}** "
                f"(${profile['avg_monetary']:,.0f}), "
                f"c√≥ ti·ªÅm nƒÉng tƒÉng gi√° tr·ªã ƒë∆°n h√†ng trung b√¨nh"
            )

        return "**üìä Ph√¢n t√≠ch RFM:**\n" + ". ".join(analysis_parts) + "."

    def _build_business_value_analysis(self, profile: Dict, characteristics: Dict, all_data_avg_clv: float) -> str:
        """X√¢y d·ª±ng ph√¢n t√≠ch gi√° tr·ªã kinh doanh"""
        parts = []

        # Revenue contribution
        if characteristics['revenue_contribution'] >= 30:
            parts.append(
                f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** t·ªïng doanh thu - l√† ph√¢n kh√∫c **c·ªët l√µi**")
        elif characteristics['revenue_contribution'] >= 15:
            parts.append(
                f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** doanh thu - ph√¢n kh√∫c **quan tr·ªçng**")
        else:
            parts.append(
                f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** doanh thu v·ªõi quy m√¥ {characteristics['size_percentage']:.1f}% kh√°ch h√†ng")

        # CLV
        if characteristics['avg_clv'] > all_data_avg_clv * 1.5:
            parts.append(
                f"Customer Lifetime Value ∆∞·ªõc t√≠nh **cao** (${characteristics['avg_clv']:,.0f})")

        # Churn risk
        if characteristics['churn_risk_percentage'] > 40:
            parts.append(
                f"‚ö†Ô∏è C√≥ {characteristics['churn_risk_percentage']:.0f}% kh√°ch h√†ng c√≥ **nguy c∆° churn cao**")
        elif characteristics['churn_risk_percentage'] < 15:
            parts.append(
                f"‚úì T·ª∑ l·ªá churn th·∫•p ({characteristics['churn_risk_percentage']:.0f}%), ph√¢n kh√∫c **·ªïn ƒë·ªãnh**")

        return "**üí∞ Gi√° tr·ªã kinh doanh:**\n" + ". ".join(parts) + "."

    def _build_behavior_insight(self, profile: Dict, characteristics: Dict) -> str:
        """X√¢y d·ª±ng insight v·ªÅ h√†nh vi"""
        insights = []

        # Cohesion (ƒë·ªô ƒë·ªìng nh·∫•t)
        if characteristics['cohesion_score'] < 0.5:
            insights.append(
                "Ph√¢n kh√∫c c√≥ **ƒë·ªô ƒë·ªìng nh·∫•t cao** (h√†nh vi t∆∞∆°ng ƒë·ªìng), d·ªÖ d√†ng targeting")
        elif characteristics['cohesion_score'] > 1.0:
            insights.append(
                "Ph√¢n kh√∫c c√≥ **ƒë·ªô ƒëa d·∫°ng cao**, c·∫ßn personalization chi ti·∫øt h∆°n")
        else:
            insights.append(
                "Ph√¢n kh√∫c c√≥ **ƒë·ªô ƒë·ªìng nh·∫•t v·ª´a ph·∫£i**, ph√π h·ª£p v·ªõi chi·∫øn l∆∞·ª£c segment-level")

        # Pattern recognition d·ª±a tr√™n RFM combination
        if profile['recency_score'] >= 4 and profile['frequency_score'] >= 4:
            insights.append(
                "ƒê√¢y l√† nh√≥m **kh√°ch h√†ng trung th√†nh cao**, n√™n focus v√†o retention v√† upselling")
        elif profile['recency_score'] <= 2 and profile['frequency_score'] >= 3:
            insights.append(
                "Nh√≥m **kh√°ch h√†ng ƒëang r·ªùi b·ªè** (previously loyal), c·∫ßn win-back campaign kh·∫©n c·∫•p")
        elif profile['recency_score'] >= 4 and profile['frequency_score'] <= 2:
            insights.append(
                "Nh√≥m **kh√°ch h√†ng m·ªõi** ho·∫∑c occasional buyers, ti·ªÅm nƒÉng ph√°t tri·ªÉn th√†nh loyal")
        elif profile['monetary_score'] >= 4 and profile['frequency_score'] <= 2:
            insights.append(
                "Nh√≥m **big spenders** nh∆∞ng mua √≠t, c·∫ßn chi·∫øn l∆∞·ª£c tƒÉng frequency")

        return "**üéØ Insight h√†nh vi:**\n" + ". ".join(insights) + "."

    def _build_strategy_recommendation(self, profile: Dict, characteristics: Dict) -> str:
        """X√¢y d·ª±ng chi·∫øn l∆∞·ª£c ƒë·ªÅ xu·∫•t"""
        strategies = []

        # D·ª±a tr√™n segment tier
        tier = profile['segment_tier']

        if tier == 'VIP/Champions':
            strategies.append(
                "**Chi·∫øn l∆∞·ª£c:** VIP Program, exclusive offers, personalized service")
            strategies.append(
                "**Channels:** Direct contact, premium email, exclusive events")
            strategies.append(
                "**Goal:** Maximize LTV, encourage advocacy, prevent competitor poaching")

        elif tier == 'Loyal Customers':
            strategies.append(
                "**Chi·∫øn l∆∞·ª£c:** Loyalty rewards, cross-sell/upsell, referral programs")
            strategies.append(
                "**Channels:** Email marketing, app notifications, SMS")
            strategies.append(
                "**Goal:** Maintain engagement, increase purchase frequency v√† basket size")

        elif tier == 'Potential Loyalists':
            strategies.append(
                "**Chi·∫øn l∆∞·ª£c:** Nurturing campaigns, product education, time-limited incentives")
            strategies.append(
                "**Channels:** Email drip campaigns, retargeting ads, educational content")
            strategies.append(
                "**Goal:** Convert sang loyal customers, tƒÉng repeat purchase rate")

        elif tier == 'At Risk':
            strategies.append(
                "**Chi·∫øn l∆∞·ª£c:** Re-engagement campaigns, win-back offers, satisfaction surveys")
            strategies.append(
                "**Channels:** Multi-channel (email + SMS + retargeting), urgent messaging")
            strategies.append(
                "**Goal:** Prevent churn, understand pain points, reactive")

        else:  # Lost/Hibernating
            strategies.append(
                "**Chi·∫øn l∆∞·ª£c:** Win-back campaigns v·ªõi deep discounts, ho·∫∑c deprioritize")
            strategies.append(
                "**Channels:** Low-cost channels (email only), A/B test messages")
            strategies.append(
                "**Goal:** Cost-effective reactivation, ho·∫∑c clean database")

        return "**üìã Chi·∫øn l∆∞·ª£c Marketing:**\n" + "\n".join(strategies)

    def _build_priority_assessment(self, profile: Dict, characteristics: Dict) -> str:
        """ƒê√°nh gi√° ƒë·ªô ∆∞u ti√™n"""
        # T√≠nh ƒëi·ªÉm ∆∞u ti√™n (0-100)
        priority_score = 0

        # RFM score (max 40 ƒëi·ªÉm)
        priority_score += (profile['total_rfm_score'] / 15) * 40

        # Revenue contribution (max 30 ƒëi·ªÉm)
        priority_score += min(
            characteristics['revenue_contribution'] / 50 * 30, 30)

        # Cohesion score (max 15 ƒëi·ªÉm) - c√†ng ƒë·ªìng nh·∫•t c√†ng d·ªÖ target
        priority_score += (1 - min(characteristics['cohesion_score'], 1)) * 15

        # Churn risk (max 15 ƒëi·ªÉm) - c√†ng r·ªßi ro cao c·∫ßn ∆∞u ti√™n c√†ng cao (n·∫øu l√† segment gi√° tr·ªã)
        if profile['total_rfm_score'] >= 10:  # Ch·ªâ quan t√¢m churn risk v·ªõi segment c√≥ gi√° tr·ªã
            priority_score += (
                characteristics['churn_risk_percentage'] / 100) * 15

        # Ph√¢n lo·∫°i priority
        if priority_score >= 75:
            priority_level = "üî¥ **R·∫§T CAO** (Critical)"
            roi_potential = "ROI ti·ªÅm nƒÉng: R·∫•t cao (3-5x)"
        elif priority_score >= 60:
            priority_level = "üü† **CAO** (High)"
            roi_potential = "ROI ti·ªÅm nƒÉng: Cao (2-3x)"
        elif priority_score >= 40:
            priority_level = "üü° **TRUNG B√åNH** (Medium)"
            roi_potential = "ROI ti·ªÅm nƒÉng: Trung b√¨nh (1.5-2x)"
        else:
            priority_level = "üü¢ **TH·∫§P** (Low)"
            roi_potential = "ROI ti·ªÅm nƒÉng: Th·∫•p (<1.5x) - C√¢n nh·∫Øc cost-effectiveness"

        return (
            f"**‚ö° ƒê·ªô ∆∞u ti√™n: {priority_level}**\n"
            f"Priority Score: {priority_score:.1f}/100\n"
            f"{roi_potential}\n"
            f"**Khuy·∫øn ngh·ªã:** {'ƒê·∫ßu t∆∞ ng√¢n s√°ch marketing cao' if priority_score >= 60 else '√Åp d·ª•ng chi·∫øn l∆∞·ª£c cost-effective'}"
        )


# ===========================
# C√ÅCH S·ª¨ D·ª§NG
# ===========================

def example_usage():
    """
    V√≠ d·ª• s·ª≠ d·ª•ng SegmentReasoningEngine
    """
    # Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ data v·ªõi RFM v√† cluster labels
    import pandas as pd

    # Sample data (thay b·∫±ng data th·ª±c c·ªßa b·∫°n)
    data = pd.DataFrame({
        'CustomerID': range(1000),
        'Recency': np.random.randint(1, 400, 1000),
        'Frequency': np.random.randint(1, 50, 1000),
        'Monetary': np.random.uniform(100, 10000, 1000),
        'Cluster': np.random.randint(0, 4, 1000)  # T·ª´ K-means
    })

    # Kh·ªüi t·∫°o engine
    reasoning_engine = SegmentReasoningEngine()

    # T·∫°o l√Ω do cho t·ª´ng segment
    for cluster_id in data['Cluster'].unique():
        segment_data = data[data['Cluster'] == cluster_id]

        print(f"\n{'='*80}")
        print(f"SEGMENT {cluster_id}")
        print('='*80)

        reasoning = reasoning_engine.generate_segment_reasoning(
            segment_id=cluster_id,
            segment_data=segment_data,
            all_data=data
        )

        print(reasoning)
        print()


# Fix cho global variable
def _build_business_value_analysis_fixed(self, profile: Dict, characteristics: Dict, all_data_avg_clv: float) -> str:
    """X√¢y d·ª±ng ph√¢n t√≠ch gi√° tr·ªã kinh doanh (fixed version)"""
    parts = []

    # Revenue contribution
    if characteristics['revenue_contribution'] >= 30:
        parts.append(
            f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** t·ªïng doanh thu - l√† ph√¢n kh√∫c **c·ªët l√µi**")
    elif characteristics['revenue_contribution'] >= 15:
        parts.append(
            f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** doanh thu - ph√¢n kh√∫c **quan tr·ªçng**")
    else:
        parts.append(
            f"ƒê√≥ng g√≥p **{characteristics['revenue_contribution']:.1f}%** doanh thu v·ªõi quy m√¥ {characteristics['size_percentage']:.1f}% kh√°ch h√†ng")

    # CLV
    if characteristics['avg_clv'] > all_data_avg_clv * 1.5:
        parts.append(
            f"Customer Lifetime Value ∆∞·ªõc t√≠nh **cao** (${characteristics['avg_clv']:,.0f})")

    # Churn risk
    if characteristics['churn_risk_percentage'] > 40:
        parts.append(
            f"‚ö†Ô∏è C√≥ {characteristics['churn_risk_percentage']:.0f}% kh√°ch h√†ng c√≥ **nguy c∆° churn cao**")
    elif characteristics['churn_risk_percentage'] < 15:
        parts.append(
            f"‚úì T·ª∑ l·ªá churn th·∫•p ({characteristics['churn_risk_percentage']:.0f}%), ph√¢n kh√∫c **·ªïn ƒë·ªãnh**")

    return "**üí∞ Gi√° tr·ªã kinh doanh:**\n" + ". ".join(parts) + "."


if __name__ == "__main__":
    example_usage()
